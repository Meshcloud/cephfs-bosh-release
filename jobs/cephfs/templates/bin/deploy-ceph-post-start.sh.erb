#!/bin/bash

set -x

PWD=`pwd`
user=vcap
hostname=`hostname`

ipaddr=$(ip addr | grep 'state UP' -A2 | tail -n1 | awk '{print $2}' | cut -f1  -d'/')
ifcace=$(ifconfig | grep encap:Ethernet | cut -d" " -f1)
firstadress=<%= (link("ceph-storage").instances.first.address) %>
HOSTNAMES=( $(cat /var/vcap/instance/dns/records.json | jq '.record_infos | .[] | {'host':.[11], 'id':.[12]}' | jq --raw-output --slurp '.=sort_by(.id) | .[].host') )
IPADDRESSES=( $(cat /var/vcap/instance/dns/records.json | jq '.record_infos | .[] | {'ip':.[9], 'id':.[12]}' | jq --raw-output --slurp '.=sort_by(.id) | .[].ip') )
NETWORK='<%= p("vm.network") %>'

if [ "$hostname" == "${HOSTNAMES[0]}" ]; then 
	mkdir /root/ceph-cluster
	cd /root/ceph-cluster 

	echo "Deploying monitor to $ipaddr"
	ceph-deploy new $(echo $(echo ${HOSTNAMES[0]} | sed -e 's/^"//' -e 's/"$//')) #make the admin Node to the Monitor node

	if [ ! -e "/root/ceph.conf" ]; then
        echo "Error while deploying monitor. File ceph.conf is missing - Exiting!"
        exit 1
	fi


	for hostname in "${HOSTNAMES[@]}"
	do
	 ceph-deploy install $(echo $(echo $hostname| sed -e 's/^"//' -e 's/"$//'))
	done	

	echo "public network = $NETWORK" | tee -a ceph.conf 

	ceph-deploy --overwrite-conf mon create-initial

	if [ ! -e "/root/ceph.client.admin.keyring" ] || [ ! -e "/root/ceph.bootstrap-mgr.keyring" ]; then
        echo "Error while creating initial monitor. keyring missing. Exiting!"
        exit 1
	fi

	for hostname in "${HOSTNAMES[@]}"
	do
	 ceph-deploy admin $(echo $(echo $hostname| sed -e 's/^"//' -e 's/"$//'))
	done	


	##Creating OSDS

	diskfile=$(sudo lsblk | grep /var/vcap/store |  cut -d" " -f1 | sed 's/^..//' | sed 's/.$//')
	$(su vcap)
	
	for hostname in "${HOSTNAMES[@]}"
	do
	 ceph-deploy disk zap $(echo $(echo $hostname| sed -e 's/^"//' -e 's/"$//')):$diskfile
	 ceph-deploy osd prepare $(echo $(echo $hostname| sed -e 's/^"//' -e 's/"$//')):$diskfile
	 ceph-deploy osd activate $(echo $(echo $hostname| sed -e 's/^"//' -e 's/"$//')):$diskfile
	done	

	exit 
	ceph health > /var/vcap/sys/log/cephfs/health

	#Creating Metadata Server 
	##We choose the Second Server of our cluster to be the Metada Server


	ceph-deploy mds create $(echo $(echo $${HOSTNAMES[1]}| sed -e 's/^"//' -e 's/"$//'))
	ceph-deploy install ceph-client

	#Deploy CephFS
	##Create OSD Pools

	ceph osd pool create cephfs_data 128
	ceph osd pool create cephfs_metadata 128
	ceph fs new cephfs cephfs_metadata cephfs_data
	ceph mds stat
fi	



exit 0
